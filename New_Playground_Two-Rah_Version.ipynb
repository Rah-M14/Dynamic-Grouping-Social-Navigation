{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from stable_baselines3 import PPO\n",
    "# from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import heapq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import matplotlib.patches as patches\n",
    "# import matplotlib.animation as animation\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGSN_Env(gym.Env):\n",
    "    def __init__(self, grid_size=10, max_static_obstacles=30, max_dynamic_obstacles=20, max_steps=1000):\n",
    "        super(DGSN_Env, self).__init__()\n",
    "        self.grid_size = grid_size\n",
    "        self.boundary_threshold = vel\n",
    "        self.max_static_obstacles = max_static_obstacles\n",
    "        self.max_dynamic_obstacles = max_dynamic_obstacles\n",
    "        # self.num_static_obstacles = np.random.randint(1,10)\n",
    "        # self.num_dynamic_obstacles = np.random.randint(1,21)\n",
    "        # self.agent_pos = np.array(np.random.uniform(0, self.grid_size, size=2).round(1))\n",
    "        # self.goal_pos = np.array(np.random.uniform(0, self.grid_size, size=2).round(1))\n",
    "        self.num_static_obstacles = 30\n",
    "        self.num_dynamic_obstacles = 20\n",
    "\n",
    "        self.agent_pos = np.array(np.random.randint(0, self.grid_size, size=2))\n",
    "        self.goal_pos = np.array(np.random.randint(0, self.grid_size, size=2))\n",
    "        \n",
    "        self.dynamic_obstacles = self._init_dynamic_obstacles()\n",
    "        self.static_obstacles = self._init_static_obstacles()\n",
    "        \n",
    "        self.close_call, self.discomfort, self.current_step, self.ep_no = 0, 0, 1, 0\n",
    "        self.dist_factor = 2\n",
    "        self.max_steps = max_steps\n",
    "        self.total_reward = 0\n",
    "        \n",
    "        self.action_space = spaces.Discrete(9)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            'agent': spaces.Box(low=0, high=grid_size, shape=(2,), dtype=np.float32),\n",
    "            'dyn_obs': spaces.Box(low=0, high=grid_size, shape=(self.max_dynamic_obstacles, 2), dtype=np.float32),\n",
    "            'sta_obs': spaces.Box(low=0, high=grid_size, shape=(self.max_static_obstacles, 2), dtype=np.float32)\n",
    "        })\n",
    "        \n",
    "        wandb.login()\n",
    "        wandb.init(project='DGSN_runs')\n",
    "        \n",
    "        self.safe = True\n",
    "        \n",
    "        # Evaluation Metrics\n",
    "        self.Avg_Success_Rate = 0\n",
    "        self.Avg_Collision_Rate, self.ep_collision_rate, self.collision_count = 0, 0, 0\n",
    "        self.Avg_Min_Time_To_Collision, self.min_time_to_collision = 0, 0\n",
    "        self.Avg_Wall_Collision_Rate, self.ep_wall_collision_rate, self.wall_collision_count = 0, 0, 0\n",
    "        self.Avg_Obstacle_Collision_Rate, self.ep_obstacle_collision_rate, self.obstacle_collision_count = 0, 0, 0\n",
    "        self.Avg_Human_Collision_Rate, self.ep_human_collision_rate, self.human_collision_count = 0, 0, 0\n",
    "\n",
    "        self.Avg_Timeout = 0\n",
    "        self.Avg_Path_Length = 0\n",
    "        self.Avg_Stalled_Time, self.stalled_time = 0, 0\n",
    "\n",
    "        self.Avg_Discomfort, self.ep_discomfort = 0, 0\n",
    "        self.Avg_Human_Distance, self.ep_human_distance, self.human_distance = 0, 0, 0\n",
    "        self.Avg_Closest_Human_Distance, self.closest_human_distance = 0, 0\n",
    "        self.Min_Closest_Human_Distance = 0\n",
    "        self.goal_reached = 0\n",
    "        self.timeout = 0\n",
    "\n",
    "    # def _init_static_obstacles(self):\n",
    "    #     obstacles = []\n",
    "    #     for _ in range(self.num_static_obstacles):\n",
    "    #         obstacles.append(np.random.uniform(0, self.grid_size, size=2).round(1))\n",
    "    #     return obstacles\n",
    "    \n",
    "    # def _init_dynamic_obstacles(self):\n",
    "    #     obstacles = []\n",
    "    #     for _ in range(self.num_dynamic_obstacles):\n",
    "    #         start_pos = np.random.uniform(0, self.grid_size, size=2).round(1)\n",
    "    #         end_pos = np.random.uniform(0, self.grid_size, size=2).round(1)\n",
    "    #         path = self._compute_path(start_pos, end_pos)\n",
    "    #         obstacles.append({\n",
    "    #             'start': start_pos,\n",
    "    #             'end': end_pos,\n",
    "    #             'current': start_pos.copy(),\n",
    "    #             'angle': np.rad2deg(np.arctan2(end_pos[1] - start_pos[1], end_pos[0] - start_pos[0])),\n",
    "    #             'distance': np.linalg.norm(end_pos - start_pos),\n",
    "    #             'path': path if path else []\n",
    "    #         })\n",
    "    #     return obstacles\n",
    "\n",
    "    def _init_static_obstacles(self):\n",
    "        obstacles = []\n",
    "        for _ in range(self.num_static_obstacles):\n",
    "            # obstacles.append(np.random.uniform(0, self.grid_size, size=2).round(1))\n",
    "            obstacles.append(np.array(np.random.randint(1, self.grid_size, size=2)))\n",
    "        return obstacles\n",
    "    \n",
    "    def _init_dynamic_obstacles(self):\n",
    "        obstacles = []\n",
    "        for _ in range(self.num_dynamic_obstacles):\n",
    "            # start_pos = np.random.uniform(0, self.grid_size, size=2).round(1)\n",
    "            # end_pos = np.random.uniform(0, self.grid_size, size=2).round(1)\n",
    "            start_pos = np.array(np.random.randint(0, self.grid_size, size=2))\n",
    "            end_pos = np.array(np.random.randint(0, self.grid_size, size=2))\n",
    "            path = self._compute_path(start_pos, end_pos)\n",
    "            obstacles.append({\n",
    "                'start': start_pos,\n",
    "                'end': end_pos,\n",
    "                'current': start_pos.copy(),\n",
    "                'angle': np.rad2deg(np.arctan2(self.agent_pos[1] - start_pos[1], self.agent_pos[0] - start_pos[0])),\n",
    "                'distance': np.linalg.norm(self.agent_pos - start_pos),\n",
    "                'path': path if path else []\n",
    "            })\n",
    "        return obstacles\n",
    "\n",
    "    def _compute_path(self, start, end):\n",
    "        def heuristic(a, b):\n",
    "            return np.linalg.norm(a - b)\n",
    "\n",
    "        def a_star(start, goal):\n",
    "            open_set = []\n",
    "            heapq.heappush(open_set, (0, tuple(start)))\n",
    "            came_from = {}\n",
    "            g_score = {tuple(start): 0}\n",
    "            f_score = {tuple(start): heuristic(start, goal)}\n",
    "\n",
    "            while open_set:\n",
    "                _, current = heapq.heappop(open_set)\n",
    "                current = np.array(current)\n",
    "\n",
    "                if np.array_equal(current, goal):\n",
    "                    path = []\n",
    "                    while tuple(current) in came_from:\n",
    "                        path.append(current)\n",
    "                        current = came_from[tuple(current)]\n",
    "                    path.append(start)\n",
    "                    path.reverse()\n",
    "                    return path\n",
    "                \n",
    "                val = 0.25\n",
    "                neighbors = [current + [val, 0], current + [-val, 0], current + [0, val], current + [0, -val]]\n",
    "                neighbors = [np.clip(neighbor, 0, self.grid_size - vel) for neighbor in neighbors]\n",
    "\n",
    "                for neighbor in neighbors:\n",
    "                    tentative_g_score = g_score[tuple(current)] + heuristic(current, neighbor)\n",
    "                    if tuple(neighbor) not in g_score or tentative_g_score < g_score[tuple(neighbor)]:\n",
    "                        came_from[tuple(neighbor)] = current\n",
    "                        g_score[tuple(neighbor)] = tentative_g_score\n",
    "                        f_score[tuple(neighbor)] = tentative_g_score + heuristic(neighbor, goal)\n",
    "                        heapq.heappush(open_set, (f_score[tuple(neighbor)], tuple(neighbor)))\n",
    "\n",
    "            return []\n",
    "\n",
    "        return a_star(start, end)\n",
    "    \n",
    "    # def step(self, action):\n",
    "    #     self.current_step += 1\n",
    "    #     previous_agent_pos = self.agent_pos.copy()\n",
    "    #     print(f\"Agent's Current Position {previous_agent_pos}\")\n",
    "        \n",
    "    #     if action == 0:\n",
    "    #         self.agent_pos[1] += 0.1\n",
    "    #         print(\"Action Taken : Up\")\n",
    "    #     elif action == 1:\n",
    "    #         self.agent_pos[1] -= 0.1\n",
    "    #         print(\"Action Taken : Down\")\n",
    "    #     elif action == 2:\n",
    "    #         self.agent_pos[0] -= 0.1\n",
    "    #         print(\"Action Taken : Left\")\n",
    "    #     elif action == 3:\n",
    "    #         self.agent_pos[0] += 0.1\n",
    "    #         print(\"Action Taken : Right\")\n",
    "    #     elif action == 4:\n",
    "    #         self.agent_pos += [0.1, 0.1]\n",
    "    #         print(\"Action Taken : Right-Up\")\n",
    "    #     elif action == 5:\n",
    "    #         self.agent_pos += [-0.1, 0.1]\n",
    "    #         print(\"Action Taken : Left-Up\")\n",
    "    #     elif action == 6:\n",
    "    #         self.agent_pos += [0.1, -0.1]\n",
    "    #         print(\"Action Taken : Right-Down\")\n",
    "    #     elif action == 7:\n",
    "    #         self.agent_pos += [-0.1, -0.1]\n",
    "    #         print(\"Action Taken : Left-Down\")\n",
    "    #     elif action == 8:\n",
    "    #         print(\"Action Taken : Stay Still!\")\n",
    "    #         pass\n",
    "        \n",
    "    #     self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size - 0.5)\n",
    "    #     print(f\"Agent's New Position {self.agent_pos}\")\n",
    "        \n",
    "    #     for obstacle in self.dynamic_obstacles:\n",
    "    #         if len(obstacle['path']) > 1:\n",
    "    #             obstacle['current'] = obstacle['path'].pop(0)\n",
    "    #         else:\n",
    "    #             obstacle['path'] = self._compute_path(obstacle['start'], obstacle['end'])\n",
    "        \n",
    "    #     reward = self._compute_reward(previous_agent_pos)\n",
    "    #     print(f\"Reward Obtain : {reward}\")\n",
    "    #     done = self._is_done()\n",
    "    #     if self.current_step >= self.max_steps:\n",
    "    #         done = True\n",
    "    #         reward -= 50\n",
    "    #     truncated = False\n",
    "        \n",
    "    #     return self._get_obs(), reward, done, truncated, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        self.current_step += 1\n",
    "        previous_agent_pos = self.agent_pos.copy()\n",
    "        print(f\"Agent's Current Position {previous_agent_pos}\")\n",
    "        print(f\"Goal Position : {self.goal_pos}\")\n",
    "        \n",
    "        vel = 0.25\n",
    "        \n",
    "        if action == 0:\n",
    "            self.agent_pos[1] += vel\n",
    "            print(f\"Action Taken : {action} - Up\")\n",
    "        elif action == 1:\n",
    "            self.agent_pos[1] -= vel\n",
    "            print(f\"Action Taken : {action} - Down\")\n",
    "        elif action == 2:\n",
    "            self.agent_pos[0] -= vel\n",
    "            print(f\"Action Taken : {action} - Left\")\n",
    "        elif action == 3:\n",
    "            self.agent_pos[0] += vel\n",
    "            print(f\"Action Taken : {action} - Right\")\n",
    "        elif action == 4:\n",
    "            self.agent_pos += [vel, vel]\n",
    "            print(f\"Action Taken : {action} - Right-Up\")\n",
    "        elif action == 5:\n",
    "            self.agent_pos += [-vel, vel]\n",
    "            print(f\"Action Taken : {action} - Left-Up\")\n",
    "        elif action == 6:\n",
    "            self.agent_pos += [vel, -vel]\n",
    "            print(f\"Action Taken : {action} - Right-Down\")\n",
    "        elif action == 7:\n",
    "            self.agent_pos += [-vel, -vel]\n",
    "            print(f\"Action Taken : {action} - Left-Down\")\n",
    "        elif action == 8:\n",
    "            print(f\"Action Taken : {action} - Stay Still!\")\n",
    "            self.stalled_time += 1\n",
    "            pass\n",
    "        \n",
    "        self.agent_pos = np.clip(self.agent_pos, 0, self.grid_size - 0.5)\n",
    "        print(f\"Agent's New Position {self.agent_pos}\")\n",
    "        print(f\"Steps taken : {self.current_step}\")\n",
    "        \n",
    "        for obstacle in self.dynamic_obstacles:\n",
    "            if len(obstacle['path']) > 1:\n",
    "                obstacle['current'] = obstacle['path'].pop(0)\n",
    "            else:\n",
    "                obstacle['path'] = self._compute_path(obstacle['start'], obstacle['end'])\n",
    "        \n",
    "        reward = self._compute_reward(previous_agent_pos)\n",
    "        \n",
    "        print(f\"#####################################\")\n",
    "        print(f\"Reward Obtained : {reward}\")\n",
    "        print(f\"#####################################\")\n",
    "        \n",
    "        self.total_reward += reward\n",
    "        \n",
    "        wandb.log({\"Reward\" : reward, \"Total_Reward\" : self.total_reward})\n",
    "        \n",
    "        self.done = self._is_done()\n",
    "        if self.current_step >= self.max_steps:\n",
    "            self.done = True\n",
    "            reward -= 250\n",
    "            self.timeout += 1\n",
    "            wandb.log({\"TimeOut\" : self.timeout})\n",
    "            \n",
    "            # self.reset()\n",
    "        truncated = False\n",
    "        \n",
    "        return self._get_obs(), reward, self.done, truncated, {}\n",
    "    \n",
    "    def _compute_reward(self, previous_agent_pos):\n",
    "        reward_c = 0\n",
    "        \n",
    "        if self.safe:\n",
    "            self.min_time_to_collision += 1\n",
    "        \n",
    "        previous_dist_to_goal = np.linalg.norm(previous_agent_pos - self.goal_pos)\n",
    "        current_dist_to_goal = np.linalg.norm(self.agent_pos - self.goal_pos)\n",
    "        del_distance = current_dist_to_goal - previous_dist_to_goal\n",
    "        \n",
    "        print(f\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% \\n\")\n",
    "        print(f\"Distance to the Goal : {current_dist_to_goal}\")\n",
    "        print(f\"Del_Distance : {del_distance}\")\n",
    "        \n",
    "        if (del_distance) > 0:\n",
    "            reward_c -= del_distance*self.dist_factor\n",
    "        elif (del_distance) == 0:\n",
    "            reward_c = -2\n",
    "        else:\n",
    "            reward_c += (-del_distance)*self.dist_factor*2\n",
    "            \n",
    "        print(f\"Reward from Del_Dist : {reward_c}\")\n",
    "            \n",
    "        # Check for collisions with obstacles and boundaries\n",
    "        for i, obs in enumerate(self.dynamic_obstacles):\n",
    "            distance = np.linalg.norm(obs['current'] - self.agent_pos)\n",
    "            self.human_distance += distance\n",
    "            \n",
    "            print(f\"******************************\")\n",
    "            print(f\"Obstacle #{i} Distance : {distance}\")\n",
    "            \n",
    "            if distance < 3 and distance != 0:  # Define a threshold for collision\n",
    "                self.closest_human_distance = min(self.closest_human_distance, distance)\n",
    "                self.close_call += 1\n",
    "                                \n",
    "                pen_1 = (10/distance)\n",
    "                reward_c -= pen_1  # Penalty for colliding with a dynamic obstacle\n",
    "                print(f\"Penalty Obtained : {pen_1}\")\n",
    "        \n",
    "        print(f\"Reward Post Dynamic Manouevres : {reward_c}\")\n",
    "        print(f\"******************************\")\n",
    "                \n",
    "        if any(np.array_equal(self.agent_pos, obs) for obs in self.dynamic_obstacles):\n",
    "            self.collision_count += 1\n",
    "            self.human_collision_count += 1\n",
    "            self.safe = False\n",
    "            \n",
    "            reward_c -= 25  # Penalty for colliding with a dynamic obstacle\n",
    "            print(f\"Collided with a Human!!!\")\n",
    "            print(f\"Post Human Collision Reward : {reward_c}\")\n",
    "        if any(np.array_equal(self.agent_pos, obs) for obs in self.static_obstacles):\n",
    "            self.collision_count += 1\n",
    "            self.obstacle_collision_count += 1\n",
    "            self.safe = False\n",
    "            \n",
    "            reward_c -= 15  # Penalty for colliding with a static obstacle\n",
    "            print(f\"Collided with an obstacle!!!\")\n",
    "            print(f\"Post Obstacle Collision Reward : {reward_c}\")\n",
    "        \n",
    "        if np.any(self.agent_pos <= self.boundary_threshold) or np.any(self.agent_pos >= self.grid_size - self.boundary_threshold):\n",
    "            reward_c -= 10\n",
    "            \n",
    "            print(f\"Pretty Close to the Booundary!!!\")\n",
    "            print(f\"Post Boundary Penalty Reward : {reward_c}\")\n",
    "\n",
    "        if np.any(self.agent_pos == 0) or np.any(self.agent_pos >= self.grid_size):\n",
    "            self.collision_count += 1\n",
    "            self.wall_collision_count += 1\n",
    "            self.safe = False\n",
    "            \n",
    "            reward_c -= 15  # Penalty for hitting the wall/boundary\n",
    "            print(f\"Collided with the wall!!!\")\n",
    "            print(f\"Post Wall Collision Reward : {reward_c}\")\n",
    "        \n",
    "        reward_c -= 1\n",
    "        \n",
    "        if self._is_done():\n",
    "            reward_c += 2000\n",
    "            # self.reset()\n",
    "            \n",
    "        return reward_c\n",
    "    \n",
    "    def _is_done(self):\n",
    "        return np.array_equal(self.agent_pos, self.goal_pos)\n",
    "    \n",
    "    def _get_obs(self):\n",
    "        agent_state = np.array([self.agent_pos[0], self.agent_pos[1]], dtype=np.float32)\n",
    "        dynamic_obstacle_states = np.array([(np.rad2deg(np.arctan2(self.agent_pos[1] - ob['current'][1], self.agent_pos[0] - ob['current'][0])), np.linalg.norm(self.agent_pos - ob['current'])) for ob in self.dynamic_obstacles] + \n",
    "                                           [np.zeros(2) for _ in range(self.num_dynamic_obstacles, self.max_dynamic_obstacles)], dtype=np.float32)\n",
    "        static_obstacle_states = np.array([ob[:2] for ob in self.static_obstacles] + \n",
    "                                          [np.zeros(2) for _ in range(self.num_static_obstacles, self.max_static_obstacles)], dtype=np.float32)\n",
    "        return {\n",
    "            'agent': agent_state,\n",
    "            'dyn_obs': dynamic_obstacle_states,\n",
    "            'sta_obs': static_obstacle_states\n",
    "        }\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        if not hasattr(self, 'fig'):\n",
    "            self.fig, self.ax = plt.subplots()\n",
    "            self.ax.set_xlim(0, self.grid_size)\n",
    "            self.ax.set_ylim(0, self.grid_size)\n",
    "            # Initialize markers with initial positions\n",
    "            self.agent_marker, = self.ax.plot(self.agent_pos[0], self.agent_pos[1], 'go', markersize=10)\n",
    "            self.goal_marker, = self.ax.plot(self.goal_pos[0], self.goal_pos[1], 'rx', markersize=10)\n",
    "            self.dynamic_markers = [self.ax.plot(ob['current'][0], ob['current'][1], 'mo', markersize=5)[0] for ob in self.dynamic_obstacles]\n",
    "            self.static_markers = [self.ax.plot(ob[0], ob[1], 'bs', markersize=5)[0] for ob in self.static_obstacles]\n",
    "        else:\n",
    "            # Ensure all positions are sequences\n",
    "            self.agent_marker.set_data([self.agent_pos[0]], [self.agent_pos[1]])\n",
    "            self.goal_marker.set_data([self.goal_pos[0]], [self.goal_pos[1]])\n",
    "            for marker, obstacle in zip(self.dynamic_markers, self.dynamic_obstacles):\n",
    "                marker.set_data([obstacle['current'][0]], [obstacle['current'][1]])\n",
    "            for marker, obstacle in zip(self.static_markers, self.static_obstacles):\n",
    "                marker.set_data([obstacle[0]], [obstacle[1]])\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "        plt.pause(0.001)  # Add a short pause to update the plot\n",
    "    \n",
    "    def reset(self, **kwargs):\n",
    "        \n",
    "        print(f\"PRINTING & LOGGING!!!\")\n",
    "        \n",
    "        wandb.log({\"Epiosde\" : self.ep_no})  \n",
    "        self.ep_no += 1\n",
    "        \n",
    "        self.ep_human_distance = self.human_distance/self.current_step\n",
    "        self.ep_discomfort = self.close_call/self.current_step\n",
    "        self.ep_collision_rate = self.collision_count/self.current_step\n",
    "        self.ep_wall_collision_rate = self.wall_collision_count/self.current_step\n",
    "        self.ep_obstacle_collision_rate = self.obstacle_collision_count/self.current_step\n",
    "        self.ep_human_collision_rate = self.human_collision_count/self.current_step\n",
    "\n",
    "        self.Avg_Collision_Rate = ((self.ep_no-1)*self.Avg_Collision_Rate + self.ep_collision_rate)/self.ep_no\n",
    "        self.Avg_Min_Time_To_Collision = ((self.ep_no-1)*self.Avg_Min_Time_To_Collision + self.min_time_to_collision)/self.ep_no\n",
    "        self.Avg_Wall_Collision_Rate = ((self.ep_no-1)*self.Avg_Wall_Collision_Rate + self.ep_wall_collision_rate)/self.ep_no\n",
    "        self.Avg_Obstacle_Collision_Rate = ((self.ep_no-1)*self.Avg_Obstacle_Collision_Rate + self.ep_obstacle_collision_rate)/self.ep_no\n",
    "        self.Avg_Human_Collision_Rate = ((self.ep_no-1)*self.Avg_Human_Collision_Rate + self.ep_human_collision_rate)/self.ep_no\n",
    "        self.Avg_Path_Length = ((self.ep_no-1)*self.Avg_Path_Length + self.current_step)/self.ep_no\n",
    "        self.Avg_Stalled_Time = ((self.ep_no-1)*self.Avg_Stalled_Time + self.stalled_time)/self.ep_no\n",
    "        self.Avg_Discomfort = ((self.ep_no-1)*self.Avg_Discomfort + self.ep_discomfort)/self.ep_no\n",
    "        self.Avg_Human_Distance = ((self.ep_no-1)*self.Avg_Human_Distance + self.ep_human_distance)/self.ep_no\n",
    "        self.Avg_Closest_Human_Distance = ((self.ep_no-1)*self.Avg_Closest_Human_Distance + self.closest_human_distance)/self.ep_no\n",
    "        \n",
    "        wandb.log({\"Ep_Total_Reward\" : self.total_reward, \n",
    "                   \n",
    "                   \"Ep_Collision_Count\" : self.collision_count, \"Ep_Min_Time_To_Collision\" : self.min_time_to_collision, \n",
    "                   \"Ep_Wall_Collision_Count\" : self.wall_collision_count, \"Ep_Obstacle_Collision_Count\" : self.obstacle_collision_count, \n",
    "                   \"Ep_Human_Collision_Count\" : self.human_collision_count, \"Ep_Collision_Rate\" : self.ep_collision_rate,\n",
    "                   \"Ep_Wall_Collision_Rate\" : self.ep_wall_collision_rate, \"Ep_Obstacle_Collision_Rate\" : self.ep_obstacle_collision_rate,\n",
    "                   \"Ep_Human_Collision_Rate\" : self.ep_human_collision_rate, \"Ep_Path_Length\" : self.current_step,\n",
    "                   \"Ep_Stalled_Time\" : self.stalled_time, \"Ep_Discomfort\" : self.ep_discomfort,\n",
    "                   \"Ep_Avg_Human_Distance\" : self.ep_human_distance, \"Ep_Closest_Human_Distance\" : self.closest_human_distance,\n",
    "                   \"Ep_Close_Calls\" : self.close_call, \n",
    "                   \n",
    "                   \"Avg_Collision_Rate\" : self.Avg_Collision_Rate, \"Avg_Min_Time_To_Collision\" : self.Avg_Min_Time_To_Collision,\n",
    "                   \"Avg_Wall_Collision_Rate\" : self.Avg_Wall_Collision_Rate, \"Avg_Obstacle_Collision_Rate\" : self.Avg_Obstacle_Collision_Rate,\n",
    "                   \"Avg_Human_Collision_Rate\" : self.Avg_Human_Collision_Rate, \"Avg_Path_Length\" : self.Avg_Path_Length,\n",
    "                   \"Avg_Stalled_Time\" : self.Avg_Stalled_Time, \"Avg_Discomfort\" : self.Avg_Discomfort,\n",
    "                   \"Avg_Human_Distance\" : self.Avg_Human_Distance, \"Avg_Closest_Human_Distance\" : self.Avg_Closest_Human_Distance,                   \n",
    "                   })\n",
    "        \n",
    "        print(f\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        print(f\"RUN DETAILS!!! \\n\")\n",
    "        print(f\"Ep_Total_Reward : {self.total_reward} \\n\"), \n",
    "        print(f\"Ep_Collision_Count : {self.collision_count}\")\n",
    "        print(f\"Ep_Wall_Collision_Count : {self.wall_collision_count}\")\n",
    "        print(f\"Ep_Obstacle_Collision_Count : {self.obstacle_collision_count}\")\n",
    "        print(f\"Ep_Human_Collision_Count : {self.human_collision_count}\")\n",
    "        print(f\"Ep_Min_Time_To_Collision : {self.min_time_to_collision}\")\n",
    "        print(f\"Ep_Stalled_Time : {self.stalled_time}\")\n",
    "        print(f\"Ep_Avg_Human_Distance : {self.Avg_Human_Distance}\")\n",
    "        \n",
    "        print(f\"$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\")\n",
    "        print(\"Creating the new Episode\")\n",
    "        \n",
    "    # You can optionally handle the 'seed' or other kwargs if needed\n",
    "        if 'seed' in kwargs:\n",
    "            np.random.seed(kwargs['seed'])\n",
    "\n",
    "        self.agent_pos = np.random.uniform(0, self.grid_size, size=2).round(2)\n",
    "        self.goal_pos = np.random.uniform(0, self.grid_size, size=2).round(2)\n",
    "        # self.num_static_obstacles = np.random.randint(1,10)\n",
    "        # self.num_dynamic_obstacles = np.random.randint(1,21)\n",
    "        self.num_static_obstacles = 30\n",
    "        self.num_dynamic_obstacles = 20\n",
    "        self.dynamic_obstacles = self._init_dynamic_obstacles()\n",
    "        self.static_obstacles = self._init_static_obstacles()\n",
    "        self.safe = True\n",
    "        self.done = False\n",
    "        \n",
    "        # Evaluation Metrics\n",
    "        self.Avg_Success_Rate = 0\n",
    "        self.collision_count = 0\n",
    "        self.ep_collision_rate = 0\n",
    "        self.min_time_to_collision = 0\n",
    "        self.wall_collision_count = 0\n",
    "        self.obstacle_collision_count = 0\n",
    "        self.human_collision_count = 0\n",
    "\n",
    "        self.Avg_Success_Rate = 0\n",
    "        self.ep_collision_rate, self.collision_count = 0, 0\n",
    "        self.min_time_to_collision = 0, 0\n",
    "        self.ep_wall_collision_rate, self.wall_collision_count = 0, 0\n",
    "        self.ep_obstacle_collision_rate, self.obstacle_collision_count = 0, 0\n",
    "        self.ep_human_collision_rate, self.human_collision_count = 0, 0\n",
    "        \n",
    "        self.Avg_Timeout = 0\n",
    "        self.Avg_Path_Length = 0\n",
    "        self.stalled_time = 0\n",
    "\n",
    "        self.ep_discomfort = 0\n",
    "        self.ep_human_distance, self.human_distance = 0, 0\n",
    "        self.closest_human_distance = 0\n",
    "        self.Min_Closest_Human_Distance = 0\n",
    "                \n",
    "        self.close_call, self.discomfort, self.current_step = 0, 0, 1\n",
    "        self.total_reward = 0\n",
    "        \n",
    "        print(\"*******************************************************************\\n\")\n",
    "        print(\"Initialized the environment with the following\")\n",
    "        print(\"Agent's Initial Position :\", self.agent_pos)\n",
    "        print(\"Goal Position :\", self.goal_pos)\n",
    "        print(\"Number of Static Obstacles :\", self.num_static_obstacles)\n",
    "        print(\"Static Obstacle Positions :\", self. static_obstacles)\n",
    "        print(\"Number of Dynamic Obstacles :\", self.num_dynamic_obstacles)\n",
    "        print(\"Dynamic Obstacle theta & dist :\", self. dynamic_obstacles, \"\\n\")\n",
    "        print(\"*******************************************************************\")\n",
    "        \n",
    "        return self._get_obs(), {}  # Ensure this returns a single dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "# class RenderCallback(BaseCallback):\n",
    "#     def __init__(self, env, render_freq=1, verbose=0):\n",
    "#         super(RenderCallback, self).__init__(verbose)\n",
    "#         self.env = env\n",
    "#         self.render_freq = render_freq\n",
    "\n",
    "#     def _on_step(self):\n",
    "#         if self.n_calls % self.render_freq == 0:\n",
    "#             self.env.render()\n",
    "#         return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "\n",
    "class CustomCallback(BaseCallback):\n",
    "    def __init__(self, env, render_freq=1, save_freq=100, save_path=None, verbose=0):\n",
    "        super(CustomCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "        self.render_freq = render_freq\n",
    "        self.save_freq = save_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self) -> None:\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        if self.n_calls % self.render_freq == 0:\n",
    "            self.env.render()\n",
    "        \n",
    "        if self.n_calls % self.save_freq == 0:\n",
    "            save_file = os.path.join(self.save_path, f\"model_step_{self.n_calls}.zip\")\n",
    "            self.model.save(save_file)\n",
    "            if self.verbose > 0:\n",
    "                print(f\"Model saved at step {self.n_calls} to {save_file}\")\n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:z9wvql1u) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Avg_Closest_Human_Distance</td><td>▁</td></tr><tr><td>Avg_Collision_Rate</td><td>▁</td></tr><tr><td>Avg_Discomfort</td><td>▁</td></tr><tr><td>Avg_Human_Collision_Rate</td><td>▁</td></tr><tr><td>Avg_Human_Distance</td><td>▁</td></tr><tr><td>Avg_Min_Time_To_Collision</td><td>▁</td></tr><tr><td>Avg_Obstacle_Collision_Rate</td><td>▁</td></tr><tr><td>Avg_Path_Length</td><td>▁</td></tr><tr><td>Avg_Stalled_Time</td><td>▁</td></tr><tr><td>Avg_Wall_Collision_Rate</td><td>▁</td></tr><tr><td>Ep_Avg_Human_Distance</td><td>▁</td></tr><tr><td>Ep_Close_Calls</td><td>▁</td></tr><tr><td>Ep_Closest_Human_Distance</td><td>▁</td></tr><tr><td>Ep_Collision_Count</td><td>▁</td></tr><tr><td>Ep_Discomfort</td><td>▁</td></tr><tr><td>Ep_Human_Collision_Count</td><td>▁</td></tr><tr><td>Ep_Min_Time_To_Collision</td><td>▁</td></tr><tr><td>Ep_Obstacle_Collision_Count</td><td>▁</td></tr><tr><td>Ep_Path_Length</td><td>▁</td></tr><tr><td>Ep_Stalled_Time</td><td>▁</td></tr><tr><td>Ep_Total_Reward</td><td>▁</td></tr><tr><td>Ep_Wall_Collision_Count</td><td>▁</td></tr><tr><td>Epiosde</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Avg_Closest_Human_Distance</td><td>0.0</td></tr><tr><td>Avg_Collision_Rate</td><td>0.0</td></tr><tr><td>Avg_Discomfort</td><td>0.0</td></tr><tr><td>Avg_Human_Collision_Rate</td><td>0.0</td></tr><tr><td>Avg_Human_Distance</td><td>0.0</td></tr><tr><td>Avg_Min_Time_To_Collision</td><td>0.0</td></tr><tr><td>Avg_Obstacle_Collision_Rate</td><td>0.0</td></tr><tr><td>Avg_Path_Length</td><td>1.0</td></tr><tr><td>Avg_Stalled_Time</td><td>0.0</td></tr><tr><td>Avg_Wall_Collision_Rate</td><td>0.0</td></tr><tr><td>Ep_Avg_Human_Distance</td><td>0.0</td></tr><tr><td>Ep_Close_Calls</td><td>0</td></tr><tr><td>Ep_Closest_Human_Distance</td><td>0</td></tr><tr><td>Ep_Collision_Count</td><td>0</td></tr><tr><td>Ep_Discomfort</td><td>0.0</td></tr><tr><td>Ep_Human_Collision_Count</td><td>0</td></tr><tr><td>Ep_Min_Time_To_Collision</td><td>0</td></tr><tr><td>Ep_Obstacle_Collision_Count</td><td>0</td></tr><tr><td>Ep_Path_Length</td><td>1</td></tr><tr><td>Ep_Stalled_Time</td><td>0</td></tr><tr><td>Ep_Total_Reward</td><td>0</td></tr><tr><td>Ep_Wall_Collision_Count</td><td>0</td></tr><tr><td>Epiosde</td><td>0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">kind-plasma-19</strong> at: <a href='https://wandb.ai/rebot/DGSN_runs/runs/z9wvql1u' target=\"_blank\">https://wandb.ai/rebot/DGSN_runs/runs/z9wvql1u</a><br/> View project at: <a href='https://wandb.ai/rebot/DGSN_runs' target=\"_blank\">https://wandb.ai/rebot/DGSN_runs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240626_124931-z9wvql1u\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:z9wvql1u). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Social_Navigation\\CODE\\wandb\\run-20240626_125409-3z1f3cag</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rebot/DGSN_runs/runs/3z1f3cag' target=\"_blank\">deep-music-20</a></strong> to <a href='https://wandb.ai/rebot/DGSN_runs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rebot/DGSN_runs' target=\"_blank\">https://wandb.ai/rebot/DGSN_runs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rebot/DGSN_runs/runs/3z1f3cag' target=\"_blank\">https://wandb.ai/rebot/DGSN_runs/runs/3z1f3cag</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRINTING & LOGGING!!!\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "RUN DETAILS!!! \n",
      "\n",
      "Ep_Total_Reward : 0 \n",
      "\n",
      "Ep_Collision_Count : 0\n",
      "Ep_Wall_Collision_Count : 0\n",
      "Ep_Obstacle_Collision_Count : 0\n",
      "Ep_Human_Collision_Count : 0\n",
      "Ep_Min_Time_To_Collision : 0\n",
      "Ep_Stalled_Time : 0\n",
      "Ep_Avg_Human_Distance : 0.0\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "Creating the new Episode\n",
      "*******************************************************************\n",
      "\n",
      "Initialized the environment with the following\n",
      "Agent's Initial Position : [9.15 6.69]\n",
      "Goal Position : [9.64 1.88]\n",
      "Number of Static Obstacles : 30\n",
      "Static Obstacle Positions : [array([5, 8]), array([6, 3]), array([6, 1]), array([2, 2]), array([2, 9]), array([8, 4]), array([8, 1]), array([5, 2]), array([4, 1]), array([5, 7]), array([8, 5]), array([6, 2]), array([3, 1]), array([1, 5]), array([7, 5]), array([4, 2]), array([9, 4]), array([2, 3]), array([1, 7]), array([8, 4]), array([2, 4]), array([5, 9]), array([6, 5]), array([2, 4]), array([3, 7]), array([2, 9]), array([4, 6]), array([9, 2]), array([5, 4]), array([2, 2])]\n",
      "Number of Dynamic Obstacles : 20\n",
      "Dynamic Obstacle theta & dist : [{'start': array([6, 0]), 'end': array([7, 0]), 'current': array([6, 0]), 'angle': 64.78650412852136, 'distance': 7.39449795456054, 'path': [array([6, 0]), array([6.25, 0.  ]), array([6.5, 0. ]), array([6.75, 0.  ]), array([7., 0.])]}, {'start': array([6, 6]), 'end': array([8, 1]), 'current': array([6, 6]), 'angle': 12.355359865083528, 'distance': 3.224686031228467, 'path': [array([6, 6]), array([6.  , 5.75]), array([6. , 5.5]), array([6.  , 5.25]), array([6., 5.]), array([6.  , 4.75]), array([6. , 4.5]), array([6.  , 4.25]), array([6., 4.]), array([6.  , 3.75]), array([6. , 3.5]), array([6.  , 3.25]), array([6., 3.]), array([6.  , 2.75]), array([6.25, 2.75]), array([6.25, 2.5 ]), array([6.5, 2.5]), array([6.5 , 2.25]), array([6.75, 2.25]), array([6.75, 2.  ]), array([7., 2.]), array([7.  , 1.75]), array([7.25, 1.75]), array([7.25, 1.5 ]), array([7.5, 1.5]), array([7.5 , 1.25]), array([7.75, 1.25]), array([7.75, 1.  ]), array([8., 1.])]}, {'start': array([1, 2]), 'end': array([3, 9]), 'current': array([1, 2]), 'angle': 29.918710460055426, 'distance': 9.403116504648871, 'path': [array([1, 2]), array([1.  , 2.25]), array([1. , 2.5]), array([1.  , 2.75]), array([1., 3.]), array([1.  , 3.25]), array([1. , 3.5]), array([1.  , 3.75]), array([1., 4.]), array([1.  , 4.25]), array([1. , 4.5]), array([1.  , 4.75]), array([1., 5.]), array([1.  , 5.25]), array([1. , 5.5]), array([1.  , 5.75]), array([1., 6.]), array([1.  , 6.25]), array([1. , 6.5]), array([1.  , 6.75]), array([1., 7.]), array([1.  , 7.25]), array([1.25, 7.25]), array([1.25, 7.5 ]), array([1.5, 7.5]), array([1.5 , 7.75]), array([1.75, 7.75]), array([1.75, 8.  ]), array([2., 8.]), array([2.  , 8.25]), array([2.25, 8.25]), array([2.25, 8.5 ]), array([2.5, 8.5]), array([2.5 , 8.75]), array([2.75, 8.75]), array([2.75, 9.  ]), array([3., 9.])]}, {'start': array([7, 7]), 'end': array([4, 2]), 'current': array([7, 7]), 'angle': -8.204706191568675, 'distance': 2.172233873228203, 'path': [array([7, 7]), array([7.  , 6.75]), array([7. , 6.5]), array([7.  , 6.25]), array([7., 6.]), array([7.  , 5.75]), array([7. , 5.5]), array([7.  , 5.25]), array([7., 5.]), array([6.75, 5.  ]), array([6.75, 4.75]), array([6.5 , 4.75]), array([6.5, 4.5]), array([6.25, 4.5 ]), array([6.25, 4.25]), array([6.  , 4.25]), array([6., 4.]), array([5.75, 4.  ]), array([5.75, 3.75]), array([5.5 , 3.75]), array([5.5, 3.5]), array([5.25, 3.5 ]), array([5.25, 3.25]), array([5.  , 3.25]), array([5., 3.]), array([4.75, 3.  ]), array([4.75, 2.75]), array([4.5 , 2.75]), array([4.5, 2.5]), array([4.25, 2.5 ]), array([4.25, 2.25]), array([4.  , 2.25]), array([4., 2.])]}, {'start': array([1, 7]), 'end': array([2, 6]), 'current': array([1, 7]), 'angle': -2.178298553608753, 'distance': 8.155893574587642, 'path': [array([1, 7]), array([1.  , 6.75]), array([1.25, 6.75]), array([1.25, 6.5 ]), array([1.5, 6.5]), array([1.5 , 6.25]), array([1.75, 6.25]), array([1.75, 6.  ]), array([2., 6.])]}, {'start': array([2, 4]), 'end': array([0, 7]), 'current': array([2, 4]), 'angle': 20.617493098061, 'distance': 7.639280070792012, 'path': [array([2, 4]), array([2.  , 4.25]), array([2. , 4.5]), array([2.  , 4.75]), array([2., 5.]), array([1.75, 5.  ]), array([1.75, 5.25]), array([1.5 , 5.25]), array([1.5, 5.5]), array([1.25, 5.5 ]), array([1.25, 5.75]), array([1.  , 5.75]), array([1., 6.]), array([0.75, 6.  ]), array([0.75, 6.25]), array([0.5 , 6.25]), array([0.5, 6.5]), array([0.25, 6.5 ]), array([0.25, 6.75]), array([0.  , 6.75]), array([0., 7.])]}, {'start': array([9, 0]), 'end': array([8, 3]), 'current': array([9, 0]), 'angle': 88.71555647819922, 'distance': 6.691681403055588, 'path': [array([9, 0]), array([9.  , 0.25]), array([9. , 0.5]), array([9.  , 0.75]), array([9., 1.]), array([9.  , 1.25]), array([9. , 1.5]), array([9.  , 1.75]), array([9., 2.]), array([8.75, 2.  ]), array([8.75, 2.25]), array([8.5 , 2.25]), array([8.5, 2.5]), array([8.25, 2.5 ]), array([8.25, 2.75]), array([8.  , 2.75]), array([8., 3.])]}, {'start': array([6, 5]), 'end': array([0, 4]), 'current': array([6, 5]), 'angle': 28.213911149658415, 'distance': 3.574716771997469, 'path': [array([6, 5]), array([5.75, 5.  ]), array([5.5, 5. ]), array([5.25, 5.  ]), array([5., 5.]), array([4.75, 5.  ]), array([4.5, 5. ]), array([4.25, 5.  ]), array([4., 5.]), array([3.75, 5.  ]), array([3.5, 5. ]), array([3.25, 5.  ]), array([3., 5.]), array([2.75, 5.  ]), array([2.5, 5. ]), array([2.25, 5.  ]), array([2., 5.]), array([1.75, 5.  ]), array([1.5, 5. ]), array([1.25, 5.  ]), array([1., 5.]), array([0.75, 5.  ]), array([0.75, 4.75]), array([0.5 , 4.75]), array([0.5, 4.5]), array([0.25, 4.5 ]), array([0.25, 4.25]), array([0.  , 4.25]), array([0., 4.])]}, {'start': array([4, 5]), 'end': array([5, 7]), 'current': array([4, 5]), 'angle': 18.16752588964348, 'distance': 5.420202948229892, 'path': [array([4, 5]), array([4.  , 5.25]), array([4. , 5.5]), array([4.  , 5.75]), array([4., 6.]), array([4.  , 6.25]), array([4.25, 6.25]), array([4.25, 6.5 ]), array([4.5, 6.5]), array([4.5 , 6.75]), array([4.75, 6.75]), array([4.75, 7.  ]), array([5., 7.])]}, {'start': array([3, 0]), 'end': array([0, 6]), 'current': array([3, 0]), 'angle': 47.40821644112822, 'distance': 9.087276819817916, 'path': [array([3, 0]), array([3.  , 0.25]), array([3. , 0.5]), array([3.  , 0.75]), array([3., 1.]), array([3.  , 1.25]), array([3. , 1.5]), array([3.  , 1.75]), array([3., 2.]), array([3.  , 2.25]), array([3. , 2.5]), array([3.  , 2.75]), array([3., 3.]), array([2.75, 3.  ]), array([2.75, 3.25]), array([2.5 , 3.25]), array([2.5, 3.5]), array([2.25, 3.5 ]), array([2.25, 3.75]), array([2.  , 3.75]), array([2., 4.]), array([1.75, 4.  ]), array([1.75, 4.25]), array([1.5 , 4.25]), array([1.5, 4.5]), array([1.25, 4.5 ]), array([1.25, 4.75]), array([1.  , 4.75]), array([1., 5.]), array([0.75, 5.  ]), array([0.75, 5.25]), array([0.5 , 5.25]), array([0.5, 5.5]), array([0.25, 5.5 ]), array([0.25, 5.75]), array([0.  , 5.75]), array([0., 6.])]}, {'start': array([8, 8]), 'end': array([9, 3]), 'current': array([8, 8]), 'angle': -48.721313264749746, 'distance': 1.7431580536486069, 'path': [array([8, 8]), array([8.  , 7.75]), array([8. , 7.5]), array([8.  , 7.25]), array([8., 7.]), array([8.  , 6.75]), array([8. , 6.5]), array([8.  , 6.25]), array([8., 6.]), array([8.  , 5.75]), array([8. , 5.5]), array([8.  , 5.25]), array([8., 5.]), array([8.  , 4.75]), array([8. , 4.5]), array([8.  , 4.25]), array([8., 4.]), array([8.  , 3.75]), array([8.25, 3.75]), array([8.25, 3.5 ]), array([8.5, 3.5]), array([8.5 , 3.25]), array([8.75, 3.25]), array([8.75, 3.  ]), array([9., 3.])]}, {'start': array([5, 6]), 'end': array([6, 3]), 'current': array([5, 6]), 'angle': 9.439932299234457, 'distance': 4.206970406361329, 'path': [array([5, 6]), array([5.  , 5.75]), array([5. , 5.5]), array([5.  , 5.25]), array([5., 5.]), array([5.  , 4.75]), array([5. , 4.5]), array([5.  , 4.25]), array([5., 4.]), array([5.  , 3.75]), array([5.25, 3.75]), array([5.25, 3.5 ]), array([5.5, 3.5]), array([5.5 , 3.25]), array([5.75, 3.25]), array([5.75, 3.  ]), array([6., 3.])]}, {'start': array([4, 5]), 'end': array([5, 6]), 'current': array([4, 5]), 'angle': 18.16752588964348, 'distance': 5.420202948229892, 'path': [array([4, 5]), array([4.  , 5.25]), array([4.25, 5.25]), array([4.25, 5.5 ]), array([4.5, 5.5]), array([4.5 , 5.75]), array([4.75, 5.75]), array([4.75, 6.  ]), array([5., 6.])]}, {'start': array([9, 2]), 'end': array([6, 1]), 'current': array([9, 2]), 'angle': 88.16813682156085, 'distance': 4.69239810757783, 'path': [array([9, 2]), array([8.75, 2.  ]), array([8.5, 2. ]), array([8.25, 2.  ]), array([8., 2.]), array([7.75, 2.  ]), array([7.5, 2. ]), array([7.25, 2.  ]), array([7., 2.]), array([6.75, 2.  ]), array([6.75, 1.75]), array([6.5 , 1.75]), array([6.5, 1.5]), array([6.25, 1.5 ]), array([6.25, 1.25]), array([6.  , 1.25]), array([6., 1.])]}, {'start': array([5, 8]), 'end': array([6, 1]), 'current': array([5, 8]), 'angle': -17.518960626143684, 'distance': 4.351850181244754, 'path': [array([5, 8]), array([5.  , 7.75]), array([5. , 7.5]), array([5.  , 7.25]), array([5., 7.]), array([5.  , 6.75]), array([5. , 6.5]), array([5.  , 6.25]), array([5., 6.]), array([5.  , 5.75]), array([5. , 5.5]), array([5.  , 5.25]), array([5., 5.]), array([5.  , 4.75]), array([5. , 4.5]), array([5.  , 4.25]), array([5., 4.]), array([5.  , 3.75]), array([5. , 3.5]), array([5.  , 3.25]), array([5., 3.]), array([5.  , 2.75]), array([5. , 2.5]), array([5.  , 2.25]), array([5., 2.]), array([5.  , 1.75]), array([5.25, 1.75]), array([5.25, 1.5 ]), array([5.5, 1.5]), array([5.5 , 1.25]), array([5.75, 1.25]), array([5.75, 1.  ]), array([6., 1.])]}, {'start': array([1, 4]), 'end': array([4, 1]), 'current': array([1, 4]), 'angle': 18.26605976302546, 'distance': 8.582458855130039, 'path': [array([1, 4]), array([1.  , 3.75]), array([1.25, 3.75]), array([1.25, 3.5 ]), array([1.5, 3.5]), array([1.5 , 3.25]), array([1.75, 3.25]), array([1.75, 3.  ]), array([2., 3.]), array([2.  , 2.75]), array([2.25, 2.75]), array([2.25, 2.5 ]), array([2.5, 2.5]), array([2.5 , 2.25]), array([2.75, 2.25]), array([2.75, 2.  ]), array([3., 2.]), array([3.  , 1.75]), array([3.25, 1.75]), array([3.25, 1.5 ]), array([3.5, 1.5]), array([3.5 , 1.25]), array([3.75, 1.25]), array([3.75, 1.  ]), array([4., 1.])]}, {'start': array([8, 5]), 'end': array([1, 7]), 'current': array([8, 5]), 'angle': 55.765755544742916, 'distance': 2.0441624201613733, 'path': [array([8, 5]), array([7.75, 5.  ]), array([7.5, 5. ]), array([7.25, 5.  ]), array([7., 5.]), array([6.75, 5.  ]), array([6.5, 5. ]), array([6.25, 5.  ]), array([6., 5.]), array([5.75, 5.  ]), array([5.5, 5. ]), array([5.25, 5.  ]), array([5., 5.]), array([4.75, 5.  ]), array([4.5, 5. ]), array([4.25, 5.  ]), array([4., 5.]), array([3.75, 5.  ]), array([3.5, 5. ]), array([3.25, 5.  ]), array([3., 5.]), array([2.75, 5.  ]), array([2.75, 5.25]), array([2.5 , 5.25]), array([2.5, 5.5]), array([2.25, 5.5 ]), array([2.25, 5.75]), array([2.  , 5.75]), array([2., 6.]), array([1.75, 6.  ]), array([1.75, 6.25]), array([1.5 , 6.25]), array([1.5, 6.5]), array([1.25, 6.5 ]), array([1.25, 6.75]), array([1.  , 6.75]), array([1., 7.])]}, {'start': array([5, 8]), 'end': array([7, 9]), 'current': array([5, 8]), 'angle': -17.518960626143684, 'distance': 4.351850181244754, 'path': [array([5, 8]), array([5.25, 8.  ]), array([5.5, 8. ]), array([5.75, 8.  ]), array([6., 8.]), array([6.  , 8.25]), array([6.25, 8.25]), array([6.25, 8.5 ]), array([6.5, 8.5]), array([6.5 , 8.75]), array([6.75, 8.75]), array([6.75, 9.  ]), array([7., 9.])]}, {'start': array([7, 7]), 'end': array([8, 5]), 'current': array([7, 7]), 'angle': -8.204706191568675, 'distance': 2.172233873228203, 'path': [array([7, 7]), array([7.  , 6.75]), array([7. , 6.5]), array([7.  , 6.25]), array([7., 6.]), array([7.  , 5.75]), array([7.25, 5.75]), array([7.25, 5.5 ]), array([7.5, 5.5]), array([7.5 , 5.25]), array([7.75, 5.25]), array([7.75, 5.  ]), array([8., 5.])]}, {'start': array([3, 0]), 'end': array([0, 2]), 'current': array([3, 0]), 'angle': 47.40821644112822, 'distance': 9.087276819817916, 'path': [array([3, 0]), array([2.75, 0.  ]), array([2.5, 0. ]), array([2.25, 0.  ]), array([2., 0.]), array([1.75, 0.  ]), array([1.75, 0.25]), array([1.5 , 0.25]), array([1.5, 0.5]), array([1.25, 0.5 ]), array([1.25, 0.75]), array([1.  , 0.75]), array([1., 1.]), array([0.75, 1.  ]), array([0.75, 1.25]), array([0.5 , 1.25]), array([0.5, 1.5]), array([0.25, 1.5 ]), array([0.25, 1.75]), array([0.  , 1.75]), array([0., 2.])]}] \n",
      "\n",
      "*******************************************************************\n"
     ]
    }
   ],
   "source": [
    "env = DGSN_Env()\n",
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Train','Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict('agent': Box(0.0, 10.0, (2,), float32), 'dyn_obs': Box(0.0, 10.0, (20, 2), float32), 'sta_obs': Box(0.0, 10.0, (30, 2), float32))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('agent', array([0.27366948, 3.5425    ], dtype=float32)),\n",
       "             ('dyn_obs',\n",
       "              array([[8.954283  , 1.6161731 ],\n",
       "                     [3.1297028 , 1.738426  ],\n",
       "                     [7.124418  , 5.9758883 ],\n",
       "                     [4.4182878 , 8.620987  ],\n",
       "                     [7.6363297 , 5.965099  ],\n",
       "                     [0.4397115 , 3.5781138 ],\n",
       "                     [4.8059855 , 3.4772356 ],\n",
       "                     [2.1928718 , 9.846771  ],\n",
       "                     [7.6059113 , 3.5106046 ],\n",
       "                     [6.8132787 , 7.708183  ],\n",
       "                     [5.316039  , 1.49435   ],\n",
       "                     [3.9357386 , 2.1430638 ],\n",
       "                     [0.45579088, 4.3236117 ],\n",
       "                     [9.898193  , 3.9730706 ],\n",
       "                     [3.8665802 , 5.3776464 ],\n",
       "                     [8.064304  , 6.605221  ],\n",
       "                     [3.726143  , 8.951874  ],\n",
       "                     [4.3326116 , 0.6802065 ],\n",
       "                     [7.7078757 , 1.3737779 ],\n",
       "                     [8.520579  , 3.2367256 ]], dtype=float32)),\n",
       "             ('sta_obs',\n",
       "              array([[7.881704  , 8.071902  ],\n",
       "                     [3.585649  , 8.020136  ],\n",
       "                     [2.706035  , 6.9866214 ],\n",
       "                     [1.100856  , 2.3208277 ],\n",
       "                     [3.6921167 , 0.6762853 ],\n",
       "                     [8.337653  , 1.2859775 ],\n",
       "                     [6.3802767 , 2.039127  ],\n",
       "                     [6.986605  , 3.0335188 ],\n",
       "                     [4.7703247 , 6.066022  ],\n",
       "                     [9.371282  , 5.6393104 ],\n",
       "                     [4.0647745 , 9.677538  ],\n",
       "                     [7.5865116 , 7.443815  ],\n",
       "                     [6.0077157 , 4.904495  ],\n",
       "                     [8.254788  , 1.5771167 ],\n",
       "                     [6.1891513 , 7.9617257 ],\n",
       "                     [8.505176  , 0.4944464 ],\n",
       "                     [1.2866026 , 3.5138404 ],\n",
       "                     [6.154288  , 9.450203  ],\n",
       "                     [5.338055  , 3.2995164 ],\n",
       "                     [5.359157  , 1.7813996 ],\n",
       "                     [3.9777265 , 6.4699445 ],\n",
       "                     [9.1806135 , 3.7347176 ],\n",
       "                     [3.519817  , 8.3200035 ],\n",
       "                     [0.9124745 , 8.623828  ],\n",
       "                     [6.3711157 , 8.010755  ],\n",
       "                     [0.9472722 , 4.906554  ],\n",
       "                     [0.97012204, 4.711341  ],\n",
       "                     [5.129223  , 0.12800586],\n",
       "                     [1.9406646 , 1.0568463 ],\n",
       "                     [1.6419867 , 5.865004  ]], dtype=float32))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'env' is your environment and 'model' is your RL model\n",
    "# render_callback = RenderCallback(env, render_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Train', 'Saved_Models')\n",
    "\n",
    "combined_callback = CustomCallback(env=env, render_freq=1, save_freq=1, save_path=save_path, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, tensorboard_log=log_path, device='cuda', n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAkbElEQVR4nO3df3BU9b3/8deSmN2Eki2Qkk2GrEkksygg/kAYgtOOIyPXQaZOp3rtF3v55XSmjfIjrRXagrWKEdo6DMqgOAG5U6k6c4ta71WHoYrDEPkpjk7rAgW7qcPCRGUXWDc4yfn+sZKSZhPy45w9n919PpidnT2f3T3vzTm758XZc97rsSzLEgAAgEGGuV0AAADAvyOgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjDDigvPvuu5ozZ44qKyvl8Xj0yiuvdBu3LEurVq1SRUWFiouLNXPmTB09etSuegEAQB4YcEA5f/68Jk+erA0bNqQdX7t2rdavX69nnnlGe/fu1fDhwzVr1iwlk8khFwsAAPKDZyg/FujxeLR9+3bdeeedklJ7TyorK/XTn/5UP/vZzyRJsVhM5eXlev7553XPPffYUjQAAMhthXY+2YkTJxSNRjVz5syuaX6/X9OmTVNLS0vagNLe3q729vau252dnfr88881evRoeTweO8sDAAAOsSxLZ8+eVWVlpYYNG/ohrrYGlGg0KkkqLy/vNr28vLxr7N81NTXpkUcesbMMAADgktbWVo0dO3bIz2NrQBmMFStWqLGxset2LBZTMBhUa2urSktLXawMAAD0VzweV1VVlUaMGGHL89kaUAKBgCTp1KlTqqio6Jp+6tQpXXfddWkf4/V65fV6e0wvLS0loAAAkGXsOjzD1j4oNTU1CgQC2rlzZ9e0eDyuvXv3avr06XbOCgAA5LAB70E5d+6cjh071nX7xIkTOnz4sEaNGqVgMKilS5fqscceU11dnWpqarRy5UpVVlZ2nekDAABwOQMOKAcOHNAtt9zSdfvi8SPz5s3T888/r5///Oc6f/68fvSjH+nMmTO6+eab9eabb8rn89lXNQAAyGlD6oPihHg8Lr/fr1gsxjEoAABkCbu33/wWDwAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAADS+fWvpUcfHdhjHn009TgMGQEFAIB0CgqkVav6H1IefTR1/4ICZ+vKE7b+mjEAADlj5crU9apV3W+nczGc/OY3fd8P/UZAAQCgN/0JKYQTRxBQAADoS18hhXDiGAIKAACXky6kEE4cRUABAKA/Lg0pjz0mXbhAOHGQx7Isy+0iLmX3zzUDAGArrzcVToqKpPZ2t6sxht3bb04zBgCgvx599F/h5MKFgfdJQb8RUAAA6I9Ljzlpb09dD6RPCgaEY1AAALicdAfEDqRPCgaMgAIAQF/6OluHkOIYAgoAAL3pz6nEhBRHEFAAAEhnIH1OCCm2I6AAAJBOR8fA+pxcvF9Hh3M15RH6oAAAgCGjDwoAAMh5BBQAAGAcAgoAADBO3h0kmziaUHRzVMlPkvJV+xRYGFBJXYnbZQHIAi0t0vHjPafX1krTp2e+nsGKRKS2tp7Ty8qkYDDz9QDp5FVAObnlpML3hSWPJEuSR4qsjSjUHFLF/Aq3ywNgsJYWqb6+9/E9e7IjpEQiUigkJZM9x3w+KRwmpMAMefMVT+JoIhVOOiV1qNt1eFFYiWMJdwsEYLR0e04GMm6Ktrb04URKTU+3ZwVwQ94ElOjmaGrPSToeKdoczWg9AACgd3kTUJKfJFNf66RjfT0OAACMkDcBxVft63MPiq/al9F6AABA7/ImoAQWBvrcgxJYFMhoPQAAoHd5E1BK6koUag6lXnGBul2HmkMqGcepxgB6V1s7tHFTlJWlztZJx+dLjQMmyLvf4kkcSyjafEkflEUBwgmAfqEPCtA7u7ffeRdQAACA/fixQAAAkPMIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYJxCu5+wo6NDv/71r/WHP/xB0WhUlZWVmj9/vn71q1/J4/HYPTvjRCJSW1vP6WVlUjCY+XoAE/C+QLZKHE0oujmq5CdJ+ap9CiwMqKSuxLbn573RO9sDypo1a7Rx40Zt3bpVEyZM0IEDB7RgwQL5/X4tXrzY7tkZJRKRQiEpmew55vNJ4TArHPIP7wtkq5NbTip8X1jySLIkeaTI2ohCzSFVzK8Y8vPz3uib7V/x7NmzR9/97nc1e/ZsVVdX6/vf/75uu+027du3z+5ZGaetLf2KJqWmp0vJQK7jfYFslDiaSIWTTkkd6nYdXhRW4lhiyPPgvdE32wNKfX29du7cqSNHjkiSPvjgA+3evVu333572vu3t7crHo93uwAA4Kbo5mhqz0k6HinaHM1oPfnI9q94li9frng8rvHjx6ugoEAdHR1avXq15s6dm/b+TU1NeuSRR+wuAwCAQUt+kkx9rZOO9fU4HGX7HpSXX35ZL7zwgrZt26ZDhw5p69at+t3vfqetW7emvf+KFSsUi8W6Lq2trXaXBADAgPiqfX3uQfFV+zJaTz6yfQ/Kgw8+qOXLl+uee+6RJE2aNEn/+Mc/1NTUpHnz5vW4v9frldfrtbsMAAAGLbAwoMjaSPpBSwosCmS2oDxk+x6URCKhYcO6P21BQYE6OzvtnpVxyspSR16n4/OlxoF8w/sC2aikrkSh5lBqK1mgbteh5pBKxg39VGPeG32zfQ/KnDlztHr1agWDQU2YMEHvv/++nnzySS1cuNDuWRknGEydFsY57cC/8L5AtqqYXyH/zX5Fmy/pg7IoYEs4kXhvXI7HsqzeDgMalLNnz2rlypXavn27Tp8+rcrKSv3gBz/QqlWrVFRUdNnHx+Nx+f1+xWIxlZaW2lkaAGQFp5uDAU6we/tte0AZKgIKgHyWrjmYLNnWHAxwit3bb36LBwAMkYnmYEC2IKAAgCFoDgb8CwEFAAxBczDgXwgoAGAImoMB/0JAAQBDBBYG+tyDQnMw5BMCCgAYIhPNwYBsYXujNgDA4DndHAzIFgQUADBMybgS1TbVul0G4Cq+4gEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjFLpdAMwUiUhtbT2nl5VJwWDm68lnLAvYLRfWqZYW6fjxntNra6Xp0zNfD+xHQEEPkYgUCknJZM8xn08Kh7PnQyzbsSxgt1xYp1papPr63sf37CGk5AK+4kEPbW3pP7yk1PR0//OCM1gWsFsurFPp9pwMZBzZgYACAACMQ0ABAADGIaAAAADjEFAAAIBxCCjooawsdTR/Oj5fahyZwbKA3XJhnaqtHdo4sgOnGaOHYDB1qmG290nIBSwL2C0X1qnp01OnEtMHJbd5LMuy3C7iUvF4XH6/X7FYTKWlpW6XAwAA+sHu7Tdf8QAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDiOBJRPP/1U9957r0aPHq3i4mJNmjRJBw4ccGJWcEgkIh061PMSibhdGQAgHxTa/YRffPGFZsyYoVtuuUVvvPGGvvWtb+no0aMaOXKk3bPKa5Zl6bMvP9O5C+f0jaJvaHTxaHk8HlueOxKRQiEpmew55vNJ4bAUDNoyKwAA0rI9oKxZs0ZVVVXasmVL17Samhq7Z5O3ziTPaOvhrXpq31P6+xd/75p+1cir9MDUBzTvunn6pu+bQ5pHW1v6cCKlpre1EVAAAM6y/Sue1157TVOmTNFdd92lMWPG6Prrr9dzzz3X6/3b29sVj8e7XZDeW8fe0tgnx2rZW8t0/Ivj3caOf3Fcy95aprFPjtVbx95yqUIAAOxhe0A5fvy4Nm7cqLq6Or311lv68Y9/rMWLF2vr1q1p79/U1CS/3991qaqqsruknPDWsbc0e9tsffnVl7K+/nepi9O+/OpLzd42m5ACAMhqHsuyrMvfrf+Kioo0ZcoU7dmzp2va4sWLtX//frW0tPS4f3t7u9rb27tux+NxVVVVKRaLqbS01M7SstaZ5BmNfXKsvvzqS3Wq87L3H6ZhKr6iWP9s/Oegvu45dEi68cbexw8elG64YcBPCwDIYfF4XH6/37btt+17UCoqKnTNNdd0m3b11Vcr0svpH16vV6Wlpd0u6G7r4a1KfJXoVziRpE51KvFVQv/9wX87XBkAAM6wPaDMmDFD4XC427QjR47oyiuvtHtWecGyLD2176lBPXb93vUazA6ysrLU2Trp+HypcQAAnGT7WTzLli1TfX29Hn/8cd19993at2+fNm3apE2bNtk9q7zw2ZefdTtbp78sWfr7F3/X519+rtElowf02GAwdSpxW1vPsbIyzuABADjP9oBy0003afv27VqxYoV+85vfqKamRuvWrdPcuXPtnlVeOHfh3JAef/bC2QEHFCkVQnIhiCSOJhTdHFXyk6R81T4FFgZUUlfidlkAgMuwPaBI0h133KE77rjDiafOO98o+saQHj+iaIRNlWSfk1tOKnxfWPJIsiR5pMjaiELNIVXMr3C7PABAH/gtHsONLh6tq0ZeJY8G1iXWI4+uGnmVRhWPcqgysyWOJlLhpFNSh7pdhxeFlTiWcLdAAECfCCiG83g8emDqA4N67OJpi21rf59topuj6jXTeaRoczSj9QAABoaAkgXmXTdPJVeUaFg/F9cwzzCVXFGi/5r8Xw5XZq7kJ0mptxOYrK/HAQDGIqBkgW/6vqn/uft/5PF4LhtShmmYPPLoT//5pyH/Jk8281X7+tyD4qvu5TxqAIARCChZYta4Wfrf//e/Kr6iWJ6v/13q4rTiK4r1f3P/T7dddZtLlZohsDDQ5x6UwKJARusBAAwMASWLzBo3S/9s/KfW/cc61Y6s7TZWO7JW6/5jnT5t/DTvw4kkldSVKNQcSq3hBep2HWoOqWQcpxoDgMls/y2eobK7l3+usixLn3/5uc5eOKsRRSM0qnhU3h4Q25fEsYSizZf0QVkUIJwAgAPs3n470gcFzvN4PBpdMnpQTdjyScm4EtU21V7+jgAAo/AVDwAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADBOodsF5JqWFun48Z7Ta2ul6dMzX89g5crrSBxNKLo5quQnSfmqfQosDKikrsTtspClIhGpra3n9LIyKRjMfD1ALiOg2KilRaqv7318z57s2Ljnyus4ueWkwveFJY8kS5JHiqyNKNQcUsX8CrfLQ5aJRKRQSEome475fFI4TEgB7MRXPDZKt8dhIOOmyIXXkTiaSIWTTkkd6nYdXhRW4ljC3QKRddra0ocTKTU93Z4VAINHQEFOim6OpvacpOORos3RjNYDABgYAgpyUvKTZOprnXSsr8cBAMYioCAn+ap9fe5B8VX7MloPAGBgCCjISYGFgT73oAQWBTJaDwBgYAgoNqqtHdq4KXLhdZTUlSjUHEqt4QXqdh1qDqlkHKcaY2DKylJn66Tj86XGAdjHY1lWb//PdEU8Hpff71csFlNpaanb5QxYrvQPyZXXkTiWULT5kj4oiwKEEwwafVCA3tm9/SagAACAIbN7+02jNgAZQVdfs7A8YDr2oABwXLquvrJEV1+XsDzgBLu33xwkC8BRdPU1C8sD2YKAAsBRdPU1C8sD2YKAAsBRdPU1C8sD2YKAAsBRdPU1C8sD2YKAAsBRdPU1C8sD2YKAAsBRdPU1C8sD2YLTjAFkBF19zcLygN3oJAsAAIxDHxQAAJDzCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQrdLgAAkFmRiNTW1nN6WZkUDGa+HiAdx/egPPHEE/J4PFq6dKnTswIAXEYkIoVC0o039ryEQqlxwASOBpT9+/fr2Wef1bXXXuvkbAAA/dTWJiWT6ceSyfR7VgA3OBZQzp07p7lz5+q5557TyJEje71fe3u74vF4twsAAMhvjgWUhoYGzZ49WzNnzuzzfk1NTfL7/V2Xqqoqp0oCAABZwpGA8uKLL+rQoUNqamq67H1XrFihWCzWdWltbXWiJAAAkEVsP4untbVVS5Ys0Y4dO+Tz+S57f6/XK6/Xa3cZAAAgi9m+B+XgwYM6ffq0brjhBhUWFqqwsFC7du3S+vXrVVhYqI6ODrtnCQDop7Iyqbf/O/p8qXHABLbvQbn11lv14Ycfdpu2YMECjR8/Xg899JAKCgrsniUAoJ+CQSkcpg8KzGd7QBkxYoQmTpzYbdrw4cM1evToHtMBAJkXDBJEYD5a3QMAAONkpNX9O++8k4nZAACAHMEeFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4hW4XkIsSRxOKbo4q+UlSvmqfAgsDKqkrcbsswFas5wCc5LEsy3K7iEvF43H5/X7FYjGVlpa6Xc6AndxyUuH7wpJHkqWu61BzSBXzK1yuDrAH6zmAf2f39puveGyUOJpIfWh3SupQt+vworASxxLuFgjYgPUcQCYQUGwU3RxN/U8yHY8UbY5mtB7ACaznADKBgGKj5CfJ1O7udKyvx4Esx3oOIBMIKDbyVfv6/J+lr9qX0XoAJ7CeA8gEAoqNAgsDff7PMrAokNF6ACewngPIBAKKjUrqShRqDqX+qgXqdh1qDqlkHKdgIvuxngPIBE4zdkDiWELR5kv6QywK8KGNnMN6DuBSdm+/CSjIWZGI1NbWc3pZmRQMZr6eochEU7R8bbw2kNedK+tULryOlhbp+PGe02trpenTM18PCChAv0QiUigkJdOcUOLzSeFw9nwQZ6IpWr42XhvI686VdSoXXkdLi1Rf3/v4nj2EFDfQqA3oh7a29B/AUmp6uv89migTTdHytfHaQF93rqxTufA60u05Gcg4sgMBBTBYJpqi5WvjtXx93UC2IKAABstEU7R8bbyWr68byBYEFMBgmWiKlq+N1/L1dQPZgoACGCwTTdHytfFavr5uIFsQUJCTyspSZySk4/OlxrNBJpqi5WvjtYG+7lxZp3LhddTWDm0c2YHTjJGzcqHXw0WZaIqWr43XBvK6c2WdyoXXQR8U89AHBQAAGMfu7XehDTUBwGXla6daAINDQAHguHQdWyNrIznfqRbA4HGQLABH5WunWgBDQ0AB4Cg6tgIYDAIKAEfRsRXAYBBQADiKjq0ABoOAAsBRdGwFMBgEFACOytdOtQCGhtOMATiuYn6F/Df787JTLYDBIaAYgAZWyAcl40pU28SPpADoHwKKy2hgBQBATxyD4iIaWAEAkB4BxUU0sAIAID0CiotoYAUAQHoEFBfRwAoAgPQIKC6igRUAAOkRUFxEAysAANLjNGOX0cAKAICeCCgGoIEVkLtoxAgMDgEFABxCI0Zg8DgGBQAcQCNGYGgIKADgABoxAkNDQAEAB9CIERgaAgoAOIBGjMDQEFAAwAE0YgSGhoACAA6gESMwNJxmDAAOoREjMHgEFOSsSERqa+s5vaxMCgYzX08+y+dlQSNGZ5i6TtGYzz62B5Smpib96U9/0scff6zi4mLV19drzZo1CoVCds8K6FUkIoVCUjLNiRI+nxQO5/6G0RQsC9jN1HWKxnz2sv0YlF27dqmhoUHvvfeeduzYoa+++kq33Xabzp8/b/esgF61taX/8JJS09P9zwvOYFnAbiauUzTms5/te1DefPPNbreff/55jRkzRgcPHtS3v/3tHvdvb29Xe3t71+14PG53SQAAOKo/jfn4qm9gHD+LJxaLSZJGjRqVdrypqUl+v7/rUlVV5XRJAADYisZ89nM0oHR2dmrp0qWaMWOGJk6cmPY+K1asUCwW67q0trY6WRIAALajMZ/9HD2Lp6GhQR999JF2797d6328Xq+8Xq+TZQAA4KjAwoAiayPpB2nMNyiO7UG5//779frrr+vtt9/W2LFjnZoNkFZZWepo/nR8vtQ4MoNlAbuZuE7RmM9+HsuyevvWbFAsy9IDDzyg7du365133lFdXd2AHh+Px+X3+xWLxVRaWmpnacgzpvZJyEcsC9jN1HUqcSyRt4357N5+2x5QfvKTn2jbtm169dVXu/U+8fv9Ki4uvuzjCSgAAGQf4wOKx5P+KKEtW7Zo/vz5l308AQUAgOxj9/bb9oNkbc47AAAgD/FrxgAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4zj6Y4EAAJgkcTSh6OZLWtEvDKikLj9a0WcbAgoAIC+c3HJS4fvCkkeSJckjRdZGFGoOqWJ+hdvl4d/wFQ8AIOcljiZS4aRTUoe6XYcXhZU4lnC3QPRAQAEA5Lzo5mhqz0k6HinaHM1oPbg8AgoAIOclP0mmvtZJx/p6HEYhoAAAcp6v2tfnHhRftS+j9eDyCCgAgJwXWBjocw9KYFEgo/Xg8ggoAICcV1JXolBzKLXVK1C361BzSCXjONXYNJxmDADICxXzK+S/2a9o8yV9UBYFCCeGIqAAyAgaZDmHv23/lYwrUW1TrdtloB88lmX19q2cK+LxuPx+v2KxmEpLS90uB4AN0jXIkiUaZNmAvy1MYff2m2NQADiKBlnO4W+LXEZAAeAoGmQ5h78tchkBBYCjaJDlHP62yGUEFACOokGWc/jbIpcRUAA4igZZzuFvi1xGQAHgKBpkOYe/LXIZpxkDyIjEsQQNshzC3xYmsHv7TUCxWSQitbX1nF5WJgWDma9nsFpapOPHe06vrZWmT898PRgYGnch1+XKZ20usXv7TSdZG0UiUigkJdMcOO/zSeFwdrxxWlqk+vrex/fsIaSYLF3jrsjaCI27kDNy5bMWfeMYFBu1taV/w0ip6enSvonS7TkZyDjcQ+Mu5INc+axF3wgoQA6hcReAXEFAAXIIjbsA5AoCCpBDaNwFIFcQUIAcQuMuALmCgGKjsrLUEeTp+Hyp8WxQWzu0cbiHxl3IB7nyWYu+0QfFZrlybj59ULIbjbuQ63LlszaX0KgNAAAYx+7tN1/xAAAA4xBQAACAcQgoAADAOAQUAABgHAIKAAAwDgEFAAAYh4ACAACMQ0ABAADGIaAAAADjEFAAAIBxCCgAAMA4BBQAAGAcAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGIeAAgAAjENAAQAAxiGgAAAA4xBQAACAcQgoAADAOAQUAABgHMcCyoYNG1RdXS2fz6dp06Zp3759Ts0KAADkGEcCyksvvaTGxkY9/PDDOnTokCZPnqxZs2bp9OnTTswOAADkGI9lWZbdTzpt2jTddNNNevrppyVJnZ2dqqqq0gMPPKDly5d3u297e7va29u7bsdiMQWDQbW2tqq0tNTu0gAAgAPi8biqqqp05swZ+f3+IT9foQ01dXPhwgUdPHhQK1as6Jo2bNgwzZw5Uy0tLT3u39TUpEceeaTH9KqqKrtLAwAADvvss8/MDChtbW3q6OhQeXl5t+nl5eX6+OOPe9x/xYoVamxs7Lp95swZXXnllYpEIra8QAzNxUTMHi33sSzMwbIwB8vCHBe/ARk1apQtz2d7QBkor9crr9fbY7rf72dlM0hpaSnLwxAsC3OwLMzBsjDHsGH2HN5q+0GyZWVlKigo0KlTp7pNP3XqlAKBgN2zAwAAOcj2gFJUVKQbb7xRO3fu7JrW2dmpnTt3avr06XbPDgAA5CBHvuJpbGzUvHnzNGXKFE2dOlXr1q3T+fPntWDBgss+1uv16uGHH077tQ8yj+VhDpaFOVgW5mBZmMPuZeHIacaS9PTTT+u3v/2totGorrvuOq1fv17Tpk1zYlYAACDHOBZQAAAABovf4gEAAMYhoAAAAOMQUAAAgHEIKAAAwDjGBZQNGzaourpaPp9P06ZN0759+9wuKe80NTXppptu0ogRIzRmzBjdeeedCofDbpcFSU888YQ8Ho+WLl3qdil569NPP9W9996r0aNHq7i4WJMmTdKBAwfcLivvdHR0aOXKlaqpqVFxcbGuuuoqPfroo+K8D+e9++67mjNnjiorK+XxePTKK690G7csS6tWrVJFRYWKi4s1c+ZMHT16dMDzMSqgvPTSS2psbNTDDz+sQ4cOafLkyZo1a5ZOnz7tdml5ZdeuXWpoaNB7772nHTt26KuvvtJtt92m8+fPu11aXtu/f7+effZZXXvttW6Xkre++OILzZgxQ1dccYXeeOMN/fWvf9Xvf/97jRw50u3S8s6aNWu0ceNGPf300/rb3/6mNWvWaO3atXrqqafcLi3nnT9/XpMnT9aGDRvSjq9du1br16/XM888o71792r48OGaNWuWksnkwGZkGWTq1KlWQ0ND1+2Ojg6rsrLSampqcrEqnD592pJk7dq1y+1S8tbZs2eturo6a8eOHdZ3vvMda8mSJW6XlJceeugh6+abb3a7DFiWNXv2bGvhwoXdpn3ve9+z5s6d61JF+UmStX379q7bnZ2dViAQsH772992TTtz5ozl9XqtP/7xjwN6bmP2oFy4cEEHDx7UzJkzu6YNGzZMM2fOVEtLi4uVIRaLSZJtv1CJgWtoaNDs2bO7vT+Qea+99pqmTJmiu+66S2PGjNH111+v5557zu2y8lJ9fb127typI0eOSJI++OAD7d69W7fffrvLleW3EydOKBqNdvus8vv9mjZt2oC35a7/mvFFbW1t6ujoUHl5ebfp5eXl+vjjj12qCp2dnVq6dKlmzJihiRMnul1OXnrxxRd16NAh7d+/3+1S8t7x48e1ceNGNTY26he/+IX279+vxYsXq6ioSPPmzXO7vLyyfPlyxeNxjR8/XgUFBero6NDq1as1d+5ct0vLa9FoVJLSbssvjvWXMQEFZmpoaNBHH32k3bt3u11KXmptbdWSJUu0Y8cO+Xw+t8vJe52dnZoyZYoef/xxSdL111+vjz76SM888wwBJcNefvllvfDCC9q2bZsmTJigw4cPa+nSpaqsrGRZ5AhjvuIpKytTQUGBTp061W36qVOnFAgEXKoqv91///16/fXX9fbbb2vs2LFul5OXDh48qNOnT+uGG25QYWGhCgsLtWvXLq1fv16FhYXq6Ohwu8S8UlFRoWuuuabbtKuvvlqRSMSlivLXgw8+qOXLl+uee+7RpEmT9MMf/lDLli1TU1OT26XltYvbazu25cYElKKiIt14443auXNn17TOzk7t3LlT06dPd7Gy/GNZlu6//35t375df/nLX1RTU+N2SXnr1ltv1YcffqjDhw93XaZMmaK5c+fq8OHDKigocLvEvDJjxowep9wfOXJEV155pUsV5a9EIqFhw7pvwgoKCtTZ2elSRZCkmpoaBQKBbtvyeDyuvXv3DnhbbtRXPI2NjZo3b56mTJmiqVOnat26dTp//rwWLFjgdml5paGhQdu2bdOrr76qESNGdH1v6Pf7VVxc7HJ1+WXEiBE9jv0ZPny4Ro8ezTFBLli2bJnq6+v1+OOP6+6779a+ffu0adMmbdq0ye3S8s6cOXO0evVqBYNBTZgwQe+//76efPJJLVy40O3Sct65c+d07NixrtsnTpzQ4cOHNWrUKAWDQS1dulSPPfaY6urqVFNTo5UrV6qyslJ33nnnwGZk05lGtnnqqaesYDBoFRUVWVOnTrXee+89t0vKO5LSXrZs2eJ2abAsTjN22Z///Gdr4sSJltfrtcaPH29t2rTJ7ZLyUjwet5YsWWIFg0HL5/NZtbW11i9/+Uurvb3d7dJy3ttvv512GzFv3jzLslKnGq9cudIqLy+3vF6vdeutt1rhcHjA8/FYFm33AACAWYw5BgUAAOAiAgoAADAOAQUAABiHgAIAAIxDQAEAAMYhoAAAAOMQUAAAgHEIKAAAwDgEFAAAYBwCCgAAMA4BBQAAGOf/AwvrgCDhV4xXAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at step 6144 to Train\\Saved_Models\\model_step_6144.zip\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 999        |\n",
      "|    ep_rew_mean          | -3.45e+04  |\n",
      "| time/                   |            |\n",
      "|    fps                  | 7          |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 805        |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03746629 |\n",
      "|    clip_fraction        | 0.571      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -2.08      |\n",
      "|    explained_variance   | -0.0281    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.4e+04    |\n",
      "|    n_updates            | 2000       |\n",
      "|    policy_gradient_loss | -0.124     |\n",
      "|    value_loss           | 8.3e+04    |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=1000000, callback=combined_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Train','Saved_Models', 'One_PPO')\n",
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(save_path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myRL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
